{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZTAmNDoEiI2R"
   },
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 34715,
     "status": "ok",
     "timestamp": 1538144250463,
     "user": {
      "displayName": "Masatoshi Itagaki",
      "photoUrl": "",
      "userId": "04462290006021813429"
     },
     "user_tz": -540
    },
    "id": "Yl82gWpVidFA",
    "outputId": "5b8f0677-2f32-4a31-97a1-c9b8c7915624"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 168
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1739,
     "status": "ok",
     "timestamp": 1538145625648,
     "user": {
      "displayName": "Masatoshi Itagaki",
      "photoUrl": "",
      "userId": "04462290006021813429"
     },
     "user_tz": -540
    },
    "id": "ZlRqO0Zsiun4",
    "outputId": "1528c4a6-137c-4953-f3a7-1c463cdbbfac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 2719\n",
      "-rw------- 1 root root   72252 May 25 02:44 3.6-classifying-newswires.ipynb\n",
      "-rw------- 1 root root  414705 May 25 02:34 5.2-using-convnets-with-small-datasets.ipynb\n",
      "drwx------ 2 root root    4096 Aug  5 07:59 DL4US\n",
      "-rw------- 1 root root 1546306 Jun  3 14:27 file_manupilation_test.ipynb\n",
      "-rw------- 1 root root    3766 Aug  5 12:43 google_drive_test.ipynb\n",
      "-rw------- 1 root root    3694 Aug  5 12:44 mount_google_drive.ipynb\n",
      "-rw------- 1 root root  733350 Mar 18  2018 multi-class_classification_of_handwritten_digits.ipynb のコピー\n",
      "drwx------ 3 root root    4096 Sep 28 14:19 music_gan\n"
     ]
    }
   ],
   "source": [
    "!ls -l /content/gdrive/My\\ Drive/Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1844,
     "status": "ok",
     "timestamp": 1538145630931,
     "user": {
      "displayName": "Masatoshi Itagaki",
      "photoUrl": "",
      "userId": "04462290006021813429"
     },
     "user_tz": -540
    },
    "id": "DjxNc97oi6vJ",
    "outputId": "0d5466db-7bc2-4075-df26-83785f2c2218"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘/content/gdrive/My Drive/Colab/music_gan’: File exists\n"
     ]
    }
   ],
   "source": [
    "!mkdir /content/gdrive/My\\ Drive/Colab/music_gan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2285,
     "status": "ok",
     "timestamp": 1538145638013,
     "user": {
      "displayName": "Masatoshi Itagaki",
      "photoUrl": "",
      "userId": "04462290006021813429"
     },
     "user_tz": -540
    },
    "id": "wJnIAajQjtts",
    "outputId": "076e1513-3bf1-4a1f-db42-f10f3d493309"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: music21 in /usr/local/lib/python3.6/dist-packages (5.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install music21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 38398,
     "status": "ok",
     "timestamp": 1538144894626,
     "user": {
      "displayName": "Masatoshi Itagaki",
      "photoUrl": "",
      "userId": "04462290006021813429"
     },
     "user_tz": -540
    },
    "id": "mGQXsSMYk51N",
    "outputId": "825d6825-038b-483a-9914-99218647f4f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'keras-composer'...\n",
      "remote: Enumerating objects: 219, done.\u001b[K\n",
      "remote: Total 219 (delta 0), reused 0 (delta 0), pack-reused 219\u001b[K\n",
      "Receiving objects: 100% (219/219), 1.22 GiB | 37.09 MiB/s, done.\n",
      "Resolving deltas: 100% (30/30), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/masa-ita/keras-composer.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8Atf5xLfiI2V"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import pickle\n",
    "import numpy\n",
    "from music21 import converter, instrument, note, chord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YF2mi0oGiI2b"
   },
   "outputs": [],
   "source": [
    "def parse_midi_files():\n",
    "    \"\"\" Get all the notes and chords from the midi files in the ./midi_songs directory \"\"\"\n",
    "    notes = []\n",
    "    songs = []\n",
    "\n",
    "    for file in glob.glob(\"keras-composer/midi_songs/*.mid\"):\n",
    "        song = []\n",
    "        midi = converter.parse(file)\n",
    "\n",
    "        print(\"Parsing %s\" % file)\n",
    "\n",
    "        notes_to_parse = None\n",
    "\n",
    "        try: # file has instrument parts\n",
    "            s2 = instrument.partitionByInstrument(midi)\n",
    "            notes_to_parse = s2.parts[0].recurse() \n",
    "        except: # file has notes in a flat structure\n",
    "            notes_to_parse = midi.flat.notes\n",
    "\n",
    "        for element in notes_to_parse:\n",
    "            if isinstance(element, note.Note):\n",
    "                song.append(str(element.pitch))\n",
    "            elif isinstance(element, chord.Chord):\n",
    "                song.append('.'.join(str(n) for n in element.normalOrder))\n",
    "        songs.append(song)\n",
    "        notes += song\n",
    "\n",
    "    return notes, songs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3086,
     "status": "ok",
     "timestamp": 1538145654884,
     "user": {
      "displayName": "Masatoshi Itagaki",
      "photoUrl": "",
      "userId": "04462290006021813429"
     },
     "user_tz": -540
    },
    "id": "x3-3y_8iiI2f",
    "outputId": "e9a9ddaf-d6c2-430c-f3ab-e861d06af0e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing keras-composer/midi_songs/bwv777.mid\n",
      "Parsing keras-composer/midi_songs/bwv776.mid\n",
      "Parsing keras-composer/midi_songs/bwv774.mid\n",
      "Parsing keras-composer/midi_songs/bwv785.mid\n",
      "Parsing keras-composer/midi_songs/bwv778.mid\n",
      "Parsing keras-composer/midi_songs/bwv772.mid\n",
      "Parsing keras-composer/midi_songs/bwv786.mid\n",
      "Parsing keras-composer/midi_songs/bwv773.mid\n",
      "Parsing keras-composer/midi_songs/bwv779.mid\n",
      "Parsing keras-composer/midi_songs/bwv781.mid\n",
      "Parsing keras-composer/midi_songs/bwv783.mid\n",
      "Parsing keras-composer/midi_songs/bwv784.mid\n",
      "Parsing keras-composer/midi_songs/bwv782.mid\n",
      "Parsing keras-composer/midi_songs/bwv775.mid\n",
      "Parsing keras-composer/midi_songs/bwv780.mid\n"
     ]
    }
   ],
   "source": [
    "notes, songs = parse_midi_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BBJX2gQdiI2m"
   },
   "outputs": [],
   "source": [
    "max_length = 100\n",
    "\n",
    "pitchnames = sorted(set(item for item in notes))\n",
    "n_vocab = len(pitchnames)\n",
    "\n",
    "note_to_int = dict((note, number) for number, note in enumerate(pitchnames))\n",
    "int_to_note = dict([[number, note] for note, number in note_to_int.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kv6yWYdAiI2q"
   },
   "outputs": [],
   "source": [
    "def prepare_sequences(notes, sequence_length=100):\n",
    "    # get all pitch names\n",
    "    pitchnames = sorted(set(item for item in notes))\n",
    "    n_vocab = len(pitchnames)\n",
    "    \n",
    "    # convert notes to one-hot encoded\n",
    "    one_hot_notes = []\n",
    "    for note in notes:\n",
    "        one_hot_note = np.zeros(n_vocab)\n",
    "        one_hot_note[note_to_int[note]] = 1\n",
    "        one_hot_notes.append(one_hot_note)\n",
    "\n",
    "    network_input = []\n",
    "    network_output = []\n",
    "\n",
    "    # create input sequences and the corresponding outputs\n",
    "    for i in range(0, len(one_hot_notes) - sequence_length, 1):\n",
    "        sequence_in = one_hot_notes[i:i + sequence_length]\n",
    "        sequence_out = one_hot_notes[i + sequence_length]\n",
    "        network_input.append(sequence_in)\n",
    "        network_output.append(sequence_out)\n",
    "\n",
    "    n_patterns = len(network_input)\n",
    "\n",
    "    # reshape the input into a format compatible with LSTM layers\n",
    "    network_input = numpy.reshape(network_input, (n_patterns, sequence_length, n_vocab))\n",
    "\n",
    "    network_output = np.array(network_output)\n",
    "\n",
    "    return (network_input, network_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rDcxqeBLiI2s"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "network_input, network_output = prepare_sequences(notes, sequence_length=max_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8R6MGifniI2v"
   },
   "source": [
    "## Generator Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2717,
     "status": "ok",
     "timestamp": 1538145672617,
     "user": {
      "displayName": "Masatoshi Itagaki",
      "photoUrl": "",
      "userId": "04462290006021813429"
     },
     "user_tz": -540
    },
    "id": "hyoaNsTRiI2x",
    "outputId": "024bf533-9cec-4801-b98e-0d995ef983df"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "repeat_vector_1 (RepeatVecto (None, 100, 32)           0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100, 512)          1116160   \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 100, 124)          63612     \n",
      "=================================================================\n",
      "Total params: 1,179,772\n",
      "Trainable params: 1,179,772\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "import numpy as np\n",
    "\n",
    "latent_dim = 32\n",
    "n_vocab = 124\n",
    "max_length = 100\n",
    "\n",
    "generator_input = keras.Input(shape=(latent_dim,))\n",
    "\n",
    "x = layers.RepeatVector(max_length)(generator_input)\n",
    "x = layers.LSTM(512, return_sequences=True)(x)\n",
    "    \n",
    "x = layers.TimeDistributed(layers.Dense(n_vocab, activation='softmax'))(x)\n",
    "\n",
    "generator = keras.models.Model(generator_input, x)\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "694R1Rc6iI22"
   },
   "source": [
    "## Discriminator Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1630,
     "status": "ok",
     "timestamp": 1538145677183,
     "user": {
      "displayName": "Masatoshi Itagaki",
      "photoUrl": "",
      "userId": "04462290006021813429"
     },
     "user_tz": -540
    },
    "id": "0HRw5Sj-iI22",
    "outputId": "3823a50b-7a95-45b9-9e59-11cf35305e44"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 100, 124)          0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 512)               1304576   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 1,305,089\n",
      "Trainable params: 1,305,089\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator_input = layers.Input(shape=(max_length, n_vocab))\n",
    "x = layers.LSTM(512)(discriminator_input)\n",
    "x = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "discriminator = keras.models.Model(discriminator_input, x)\n",
    "discriminator.summary()\n",
    "\n",
    "discriminator_optimizer = keras.optimizers.RMSprop(lr=0.0008, clipvalue=1.0, decay=1e-8)\n",
    "discriminator.compile(optimizer=discriminator_optimizer, loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xKz_zQHDiI26"
   },
   "source": [
    "## Adversarial Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RYItN7MWiI27"
   },
   "outputs": [],
   "source": [
    "discriminator.trainable = False\n",
    "\n",
    "gan_input = keras.Input(shape=(latent_dim,))\n",
    "gan_output = discriminator(generator(gan_input))\n",
    "gan = keras.models.Model(gan_input, gan_output)\n",
    "\n",
    "gan_optimizer = keras.optimizers.RMSprop(lr=0.0004, clipvalue=1.0, decay=1e-8)\n",
    "gan.compile(optimizer=gan_optimizer, loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 720,
     "status": "ok",
     "timestamp": 1538145684245,
     "user": {
      "displayName": "Masatoshi Itagaki",
      "photoUrl": "",
      "userId": "04462290006021813429"
     },
     "user_tz": -540
    },
    "id": "AFpcE7CaiI2_",
    "outputId": "b07ec533-f133-4f51-8467-2e323e2a9045"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "model_1 (Model)              (None, 100, 124)          1179772   \n",
      "_________________________________________________________________\n",
      "model_2 (Model)              (None, 1)                 1305089   \n",
      "=================================================================\n",
      "Total params: 2,484,861\n",
      "Trainable params: 1,179,772\n",
      "Non-trainable params: 1,305,089\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gan.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NUif80i0iI3D"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from music21 import instrument, note, stream, chord\n",
    "\n",
    "def create_midi(prediction_output, file_path):\n",
    "    \"\"\" convert the output from the prediction to notes and create a midi file\n",
    "        from the notes \"\"\"\n",
    "    offset = 0\n",
    "    output_notes = []\n",
    "\n",
    "    # create note and chord objects based on the values generated by the model\n",
    "    for pattern in prediction_output:\n",
    "        # pattern is a chord\n",
    "        if ('.' in pattern) or pattern.isdigit():\n",
    "            notes_in_chord = pattern.split('.')\n",
    "            notes = []\n",
    "            for current_note in notes_in_chord:\n",
    "                new_note = note.Note(int(current_note))\n",
    "                new_note.storedInstrument = instrument.Piano()\n",
    "                notes.append(new_note)\n",
    "            new_chord = chord.Chord(notes)\n",
    "            new_chord.offset = offset\n",
    "            output_notes.append(new_chord)\n",
    "        # pattern is a note\n",
    "        else:\n",
    "            new_note = note.Note(pattern)\n",
    "            new_note.offset = offset\n",
    "            new_note.storedInstrument = instrument.Piano()\n",
    "            output_notes.append(new_note)\n",
    "\n",
    "        # increase offset each iteration so that notes do not stack\n",
    "        offset += 0.5\n",
    "\n",
    "    midi_stream = stream.Stream(output_notes)\n",
    "    midi_stream.write('midi', fp=file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 3481
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7728548,
     "status": "ok",
     "timestamp": 1538153421678,
     "user": {
      "displayName": "Masatoshi Itagaki",
      "photoUrl": "",
      "userId": "04462290006021813429"
     },
     "user_tz": -540
    },
    "id": "U4xrXYsXiI3G",
    "outputId": "eade6c48-f44c-48bb-93f8-3723378143ca"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:975: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Variable *= will be deprecated. Use `var.assign(var * other)` if you want assignment to the variable value or `x = x * y` if you want a new python Tensor object.\n",
      "discriminator loss at step 0: 0.69232357\n",
      "adversarial loss at step 0: 0.7506485\n",
      "discriminator loss at step 100: 0.18346593\n",
      "adversarial loss at step 100: 2.6398983\n",
      "discriminator loss at step 200: 0.7019431\n",
      "adversarial loss at step 200: 0.79803926\n",
      "discriminator loss at step 300: 0.70757926\n",
      "adversarial loss at step 300: 0.7202981\n",
      "discriminator loss at step 400: 0.44201237\n",
      "adversarial loss at step 400: 1.2740093\n",
      "discriminator loss at step 500: 0.07860909\n",
      "adversarial loss at step 500: 2.701179\n",
      "discriminator loss at step 600: 0.54195476\n",
      "adversarial loss at step 600: 1.4176133\n",
      "discriminator loss at step 700: 0.15213458\n",
      "adversarial loss at step 700: 1.8182348\n",
      "discriminator loss at step 800: 0.69518197\n",
      "adversarial loss at step 800: 0.7689659\n",
      "discriminator loss at step 900: 0.77287316\n",
      "adversarial loss at step 900: 1.8394969\n",
      "discriminator loss at step 1000: 0.6956809\n",
      "adversarial loss at step 1000: 0.72572577\n",
      "discriminator loss at step 1100: 0.69938827\n",
      "adversarial loss at step 1100: 0.747793\n",
      "discriminator loss at step 1200: 0.6901835\n",
      "adversarial loss at step 1200: 0.7620827\n",
      "discriminator loss at step 1300: 0.68951654\n",
      "adversarial loss at step 1300: 0.7686491\n",
      "discriminator loss at step 1400: 0.6839704\n",
      "adversarial loss at step 1400: 0.73483384\n",
      "discriminator loss at step 1500: 0.6940036\n",
      "adversarial loss at step 1500: 0.7236103\n",
      "discriminator loss at step 1600: 0.6782657\n",
      "adversarial loss at step 1600: 0.7695878\n",
      "discriminator loss at step 1700: 0.2731165\n",
      "adversarial loss at step 1700: 2.5509248\n",
      "discriminator loss at step 1800: 0.54727966\n",
      "adversarial loss at step 1800: 0.7844589\n",
      "discriminator loss at step 1900: 0.50850236\n",
      "adversarial loss at step 1900: 1.4146194\n",
      "discriminator loss at step 2000: 0.37228206\n",
      "adversarial loss at step 2000: 1.8912796\n",
      "discriminator loss at step 2100: 0.19426925\n",
      "adversarial loss at step 2100: 2.256681\n",
      "discriminator loss at step 2200: 0.6204265\n",
      "adversarial loss at step 2200: 1.0642474\n",
      "discriminator loss at step 2300: 0.63424414\n",
      "adversarial loss at step 2300: 0.8382616\n",
      "discriminator loss at step 2400: 1.4218247\n",
      "adversarial loss at step 2400: 2.087189\n",
      "discriminator loss at step 2500: 0.41898555\n",
      "adversarial loss at step 2500: 1.5300261\n",
      "discriminator loss at step 2600: 0.52026093\n",
      "adversarial loss at step 2600: 1.3082901\n",
      "discriminator loss at step 2700: 0.59903896\n",
      "adversarial loss at step 2700: 1.258816\n",
      "discriminator loss at step 2800: 0.5062243\n",
      "adversarial loss at step 2800: 0.8845788\n",
      "discriminator loss at step 2900: 0.5271718\n",
      "adversarial loss at step 2900: 1.274567\n",
      "discriminator loss at step 3000: 0.34126133\n",
      "adversarial loss at step 3000: 1.5600771\n",
      "discriminator loss at step 3100: 0.33906204\n",
      "adversarial loss at step 3100: 2.1026657\n",
      "discriminator loss at step 3200: 0.22410373\n",
      "adversarial loss at step 3200: 2.7117815\n",
      "discriminator loss at step 3300: 0.50002587\n",
      "adversarial loss at step 3300: 2.2639217\n",
      "discriminator loss at step 3400: 0.2605044\n",
      "adversarial loss at step 3400: 2.3285625\n",
      "discriminator loss at step 3500: 0.2073637\n",
      "adversarial loss at step 3500: 2.1301782\n",
      "discriminator loss at step 3600: 0.92772293\n",
      "adversarial loss at step 3600: 1.1510433\n",
      "discriminator loss at step 3700: 0.5725456\n",
      "adversarial loss at step 3700: 1.4690018\n",
      "discriminator loss at step 3800: 0.07614491\n",
      "adversarial loss at step 3800: 3.9985366\n",
      "discriminator loss at step 3900: 0.097233154\n",
      "adversarial loss at step 3900: 3.493978\n",
      "discriminator loss at step 4000: 0.47252065\n",
      "adversarial loss at step 4000: 1.4526751\n",
      "discriminator loss at step 4100: 0.34759918\n",
      "adversarial loss at step 4100: 2.259261\n",
      "discriminator loss at step 4200: 0.5096315\n",
      "adversarial loss at step 4200: 1.4520504\n",
      "discriminator loss at step 4300: 0.30145127\n",
      "adversarial loss at step 4300: 2.348732\n",
      "discriminator loss at step 4400: 0.2286654\n",
      "adversarial loss at step 4400: 2.5274096\n",
      "discriminator loss at step 4500: 0.7109247\n",
      "adversarial loss at step 4500: 2.5696354\n",
      "discriminator loss at step 4600: 0.037489027\n",
      "adversarial loss at step 4600: 3.455967\n",
      "discriminator loss at step 4700: 0.11791539\n",
      "adversarial loss at step 4700: 2.6008453\n",
      "discriminator loss at step 4800: 0.2475874\n",
      "adversarial loss at step 4800: 1.9013195\n",
      "discriminator loss at step 4900: 0.04085825\n",
      "adversarial loss at step 4900: 4.3324914\n",
      "discriminator loss at step 5000: 0.08231765\n",
      "adversarial loss at step 5000: 3.9329808\n",
      "discriminator loss at step 5100: 0.29832286\n",
      "adversarial loss at step 5100: 3.5548573\n",
      "discriminator loss at step 5200: 0.4288693\n",
      "adversarial loss at step 5200: 1.9622082\n",
      "discriminator loss at step 5300: 0.032728985\n",
      "adversarial loss at step 5300: 5.4671965\n",
      "discriminator loss at step 5400: 0.06614\n",
      "adversarial loss at step 5400: 4.8921366\n",
      "discriminator loss at step 5500: 0.32414755\n",
      "adversarial loss at step 5500: 1.7957823\n",
      "discriminator loss at step 5600: 0.64978755\n",
      "adversarial loss at step 5600: 1.6007227\n",
      "discriminator loss at step 5700: 0.06909864\n",
      "adversarial loss at step 5700: 4.2249475\n",
      "discriminator loss at step 5800: 0.23743942\n",
      "adversarial loss at step 5800: 4.1977563\n",
      "discriminator loss at step 5900: 0.23110135\n",
      "adversarial loss at step 5900: 3.6723437\n",
      "discriminator loss at step 6000: 0.104069754\n",
      "adversarial loss at step 6000: 3.382676\n",
      "discriminator loss at step 6100: 0.14686276\n",
      "adversarial loss at step 6100: 3.6836305\n",
      "discriminator loss at step 6200: 0.14561638\n",
      "adversarial loss at step 6200: 3.995969\n",
      "discriminator loss at step 6300: 0.0667639\n",
      "adversarial loss at step 6300: 5.6698685\n",
      "discriminator loss at step 6400: 0.16116449\n",
      "adversarial loss at step 6400: 4.027194\n",
      "discriminator loss at step 6500: 0.10840672\n",
      "adversarial loss at step 6500: 2.752338\n",
      "discriminator loss at step 6600: 0.22532253\n",
      "adversarial loss at step 6600: 4.2189627\n",
      "discriminator loss at step 6700: 0.35562235\n",
      "adversarial loss at step 6700: 2.8006377\n",
      "discriminator loss at step 6800: 0.17609414\n",
      "adversarial loss at step 6800: 3.676244\n",
      "discriminator loss at step 6900: 0.21507409\n",
      "adversarial loss at step 6900: 3.6547475\n",
      "discriminator loss at step 7000: 0.112102345\n",
      "adversarial loss at step 7000: 3.8045113\n",
      "discriminator loss at step 7100: 0.2731164\n",
      "adversarial loss at step 7100: 3.1475525\n",
      "discriminator loss at step 7200: 0.6220592\n",
      "adversarial loss at step 7200: 1.7455461\n",
      "discriminator loss at step 7300: 0.13963342\n",
      "adversarial loss at step 7300: 3.8590913\n",
      "discriminator loss at step 7400: 0.46982923\n",
      "adversarial loss at step 7400: 1.4598838\n",
      "discriminator loss at step 7500: 0.15148525\n",
      "adversarial loss at step 7500: 6.705269\n",
      "discriminator loss at step 7600: 0.032777652\n",
      "adversarial loss at step 7600: 3.684444\n",
      "discriminator loss at step 7700: 0.331848\n",
      "adversarial loss at step 7700: 2.2705512\n",
      "discriminator loss at step 7800: -0.02633917\n",
      "adversarial loss at step 7800: 7.250276\n",
      "discriminator loss at step 7900: 0.10658624\n",
      "adversarial loss at step 7900: 6.914183\n",
      "discriminator loss at step 8000: 0.008162064\n",
      "adversarial loss at step 8000: 7.4799013\n",
      "discriminator loss at step 8100: 0.7011687\n",
      "adversarial loss at step 8100: 1.2876823\n",
      "discriminator loss at step 8200: 0.023794184\n",
      "adversarial loss at step 8200: 15.199059\n",
      "discriminator loss at step 8300: -0.0813959\n",
      "adversarial loss at step 8300: 9.9911785\n",
      "discriminator loss at step 8400: 0.36629587\n",
      "adversarial loss at step 8400: 2.4741693\n",
      "discriminator loss at step 8500: 0.38893658\n",
      "adversarial loss at step 8500: 1.9734348\n",
      "discriminator loss at step 8600: -0.020112105\n",
      "adversarial loss at step 8600: 8.070284\n",
      "discriminator loss at step 8700: 0.3903566\n",
      "adversarial loss at step 8700: 1.8502012\n",
      "discriminator loss at step 8800: 0.08667302\n",
      "adversarial loss at step 8800: 3.103206\n",
      "discriminator loss at step 8900: 0.46937466\n",
      "adversarial loss at step 8900: 1.5154508\n",
      "discriminator loss at step 9000: 0.16614017\n",
      "adversarial loss at step 9000: 3.1042514\n",
      "discriminator loss at step 9100: 0.19925109\n",
      "adversarial loss at step 9100: 2.5262635\n",
      "discriminator loss at step 9200: 0.33174115\n",
      "adversarial loss at step 9200: 2.0315814\n",
      "discriminator loss at step 9300: 0.4353277\n",
      "adversarial loss at step 9300: 2.1709392\n",
      "discriminator loss at step 9400: 0.7337955\n",
      "adversarial loss at step 9400: 2.7592244\n",
      "discriminator loss at step 9500: 0.46547318\n",
      "adversarial loss at step 9500: 2.3197143\n",
      "discriminator loss at step 9600: 0.37403625\n",
      "adversarial loss at step 9600: 2.278983\n",
      "discriminator loss at step 9700: 0.108491674\n",
      "adversarial loss at step 9700: 3.4678206\n",
      "discriminator loss at step 9800: 0.29855457\n",
      "adversarial loss at step 9800: 3.3214748\n",
      "discriminator loss at step 9900: 0.35516888\n",
      "adversarial loss at step 9900: 1.608701\n",
      "discriminator loss at step 10000: 0.50021183\n",
      "adversarial loss at step 10000: 2.677603\n"
     ]
    }
   ],
   "source": [
    "iterations = 10001\n",
    "batch_size = 20\n",
    "save_dir = 'keras-composer'\n",
    "\n",
    "# Start training loop\n",
    "start = 0\n",
    "for step in range(iterations):\n",
    "    # Sample random points in the latent space\n",
    "    random_latent_vectors = np.random.normal(size=(batch_size, latent_dim))\n",
    "\n",
    "    # Decode them to fake images\n",
    "    generated_songs = generator.predict(random_latent_vectors)\n",
    "\n",
    "    # Combine them with real images\n",
    "    stop = start + batch_size\n",
    "    real_songs = network_input[start: stop]\n",
    "    combined_songs = np.concatenate([generated_songs, real_songs])\n",
    "\n",
    "    # Assemble labels discriminating real from fake images\n",
    "    labels = np.concatenate([np.ones((batch_size, 1)),\n",
    "                             np.zeros((batch_size, 1))])\n",
    "    # Add random noise to the labels - important trick!\n",
    "    labels += 0.05 * np.random.random(labels.shape)\n",
    "\n",
    "    # Train the discriminator\n",
    "    d_loss = discriminator.train_on_batch(combined_songs, labels)\n",
    "\n",
    "    # sample random points in the latent space\n",
    "    random_latent_vectors = np.random.normal(size=(batch_size, latent_dim))\n",
    "\n",
    "    # Assemble labels that say \"all real songs\"\n",
    "    misleading_targets = np.zeros((batch_size, 1))\n",
    "\n",
    "    # Train the generator (via the gan model,\n",
    "    # where the discriminator weights are frozen)\n",
    "    a_loss = gan.train_on_batch(random_latent_vectors, misleading_targets)\n",
    "    \n",
    "    start += batch_size\n",
    "    if start > len(network_input) - batch_size:\n",
    "      start = 0\n",
    "\n",
    "    # Occasionally save / plot\n",
    "    if step % 100 == 0:\n",
    "        # Save model weights\n",
    "        gan.save_weights('gan.h5')\n",
    "\n",
    "        # Print metrics\n",
    "        print('discriminator loss at step %s: %s' % (step, d_loss))\n",
    "        print('adversarial loss at step %s: %s' % (step, a_loss))\n",
    "\n",
    "        prediction_indices = np.argmax(generated_songs, axis=2)\n",
    "\n",
    "        prediction_song = [int_to_note[index] for index in prediction_indices[0]]\n",
    "\n",
    "        # Save Generated Song Midi\n",
    "        create_midi(prediction_song, os.path.join(save_dir, 'generated_song_' + str(step) + '.mid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xC_B-b_WiI3X"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "music_GAN.ipynb",
   "provenance": [
    {
     "file_id": "https://github.com/masa-ita/keras-composer/blob/master/music_GAN.ipynb",
     "timestamp": 1538144119666
    }
   ],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
